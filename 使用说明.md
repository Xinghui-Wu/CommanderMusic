# 针对自动语音识别系统预处理环节的实用黑盒攻击

## 项目简介

&emsp;&emsp;西安交通大学团队提出了一种攻击自动语音识别系统的新颖方法。与之前的研究针对语音识别系统底层的机器学习、深度学习模型提出的对抗攻击方法不同的是，本团队提出通过攻击语音识别系统预处理环节来达到对整个系统的攻击，使得系统误判经过特殊修改的音频样本，产生和人耳听觉感知差异较大的转录结果。

&emsp;&emsp;我们首先对攻击场景进行了充分的研究，抽象出攻击载体的概念，并相应提出指定载体和无载体两种攻击场景和攻击方法。对于指定载体这种情况，考虑以某种技术将恶意指令隐蔽地嵌入到任意的歌曲片段中，在保证用户不会察觉到恶意样本的异常的前提下，期望目标语音识别系统能够识别出隐藏于恶意歌曲样本中的指令。我们认为这是一种十分贴近于用户日常生活的实用场景，具备较高的研究价值。对于无载体这种场景，将从目标指令出发，将其扭曲成某种噪声，使得用户无法识别但却能够被语音系统转录。

&emsp;&emsp;针对指定载体的攻击场景，本团队提出的攻击方法的基本思想是精心设计扰动，将其添加至原始歌曲片段中，期望经过扰动的歌曲片段经过语音特征提取得到的特征向量与原始指令音频的特征向量尽可能相似，在此过程中，还要保持扰动尽可能小以不被察觉。这一基本思想可以抽象成优化模型，编写代码求解优化模型以生成恶意音频样本。针对无载体的攻击场景，从目标指令的特征向量出发，尝试逆转其特征提取过程，从而找到具有相似特征向量的时域信号作为恶意音频样本。

&emsp;&emsp;本团队实现了所提出的针对语音识别系统的黑盒攻击方法，并提供了若干工具用于定制化的攻击，主要包括根据给定输入指令、歌曲载体集合生成恶意样本集合的攻击脚本，给定指令文本合成指令音频文件的语音合成脚本（基于百度语音合成API、Google语音合成API），给定测试音频文件集合输出转录结果的语音识别脚本（集成了百度和科大讯飞语音识别API）。

&emsp;&emsp;下面，首先介绍我们提出的攻击方法，然后将对我们提供的几个工具进行详细的使用说明。


## 攻击方法

1. 指定载体的攻击场景

&emsp;&emsp;我们注意到这样一个事实：人耳听觉感知差异较大的两段音频经过特征提取，可能会得到相似的特征向量。因此，我们提出攻击者可以在指定载体的邻域范围内，寻找与目标指令特征向量相似的样本。例如，任意给定一个指令音频command，以及与其等时长的歌曲片段song，已知特征提取函数为MFCC()。我们目标找到一个最优扰动向量delta，当其添加到歌曲片段song后，得到的恶意样本的特征向量与目标指令相似。这一基本思想可以描述为：

<center>min ||MFCC(song + delta) - MFCC(command)||, s.t. ||delta|| < epsilon</center>

&emsp;&emsp;求解这一非线性约束的非线性优化模型找到最优扰动向量，从而生成恶意样本。为了简化优化模型，我们将约束条件作为惩罚项加入到目标函数中，约束条件前的系数称为惩罚因子。显然，惩罚因子越大，对于扰动程度的限制越强。因此，改写后的优化模型为：

<center>min ||MFCC(song + delta) - MFCC(command)|| + penalty_factor * ||delta||</center>

2. 无载体的攻击场景

&emsp;&emsp;此类攻击场景不需要考虑将恶意指令嵌入到某种载体中，只需要生成的恶意样本的听觉感知和目标指令相差较大即可。因此，我们从目标指令的MFCC特征向量出发，调用Librosa库的相关函数（基于Griffin-Lim算法），倒转MFCC特征提取过程，得到新的时域信号，并对新得到的时域信号重复上述过程，即可不断扭曲原始指令。由于MFCC特征提取过程不完全可逆，因此迭代次数越多，原始指令的失真越明显，但与原始指令MFCC特征向量的距离也越远。


## 运行环境与依赖

&emsp;&emsp;我们仅在以下平台进行了代码测试。

* 操作系统：Ubuntu 16.04.7 LTS (GNU/Linux 4.4.0-190-generic x86_64)
* 解释器：Python 3.7
* 主要第三方库：torch 1.5.0，torchaudio 0.5.0

&emsp;&emsp;完整的第三方库依赖可参见项目根目录下的requirements.txt文件。通过`pip install -r requirements.txt`命令完成环境配置。

&emsp;&emsp;由于代码中使用了PyTorch的优化器进行大规模非线性优化问题的求解，我们建议用户使用**GPU服务器**作为计算平台。


## 数据准备

1. 指令音频文件

&emsp;&emsp;我们提供了中文语音合成脚本text_to_speech.py供用户将指定的字符串文本合成为相应的音频文件。下面，提供一个例子来说明该脚本的使用。

`python text_to_speech.py -c ./Audio Samples/Commands.txt -d ./Audio Samples/Commands/`

* -c(--commands)参数指定了包含目标指令文本的文本文件（每行一段指令文本）的路径；
* -d(--directory)参数指定了语音合成音频文件的保存目录；
* -l(--language)参数指定了语音识别语种。

2. 载体歌曲文件

&emsp;&emsp;用户可从互联网上下载任意歌曲文件（wav格式），运行我们提供的preprocessing.py脚本将其转换成单声道、16kHz采样率。下面，提供一个例子来说明该脚本的使用。

`python preprocessing.py -s ./Audio Samples/Songs/`

* -s(--song)参数指定了待转换处理的歌曲文件所在的目录。


## 生成恶意音频样本

1. 指定载体的攻击场景

&emsp;&emsp;根据用户提供的原始指令音频文件集合和原始歌曲文件集合，attack.py攻击脚本将前者中的每一个指令嵌入到后者中的每一首歌曲中，并将恶意样本音频文件和作为对比的干净样本音频文件输出至用户指定的目录下。攻击脚本在进行非线性优化模型求解时，将会使用到用户指定的参数，包括优化器种类、惩罚因子、学习率和最大迭代次数。这些参数值的选取将会显著影响攻击效果。下面，提供一个例子来说明该脚本的使用。

`python attack.py -c ./Audio Samples/Commands/ -s ./Audio Samples/Songs/ -p ./Audio Samples/Pure Samples/ -m ./Audio Samples/Malicious Samples/ -t ./Audio Samples/Commands.txt -o Adam -f 50 -l 0.001 -n 10000`

* -c(--commands)参数指定了原始指令音频文件集合的目录；
* -s(--songs)参数指定了原始歌曲文件集合的目录；
* -p(--pure_samples)参数指定了生成的干净样本音频文件的输出目录；
* -m(--malicious_samples)参数指定了生成的恶意样本音频文件的输出目录；
* -t(--transcriptions)参数指定了包含原始指令文本的文本文件路径，用于输出对应于恶意样本的目标转录结果；
* -i(--interval)参数指定了截取歌曲的时间间隔；
* -o(--optimizer)参数指定了PyTorch内置优化器的种类，目前支持Adam优化器和SGD优化器；
* -f(--penalty_factor)参数指定了惩罚因子的大小，**惩罚因子用于限制优化模型中扰动向量范数对于目标函数的影响程度**，惩罚因子越大，生成的恶意样本隐蔽性越好，但攻击成功率可能欠佳，反之，恶意样本的攻击成功率较为理想，但隐蔽性较差；
* -l(--learning_rate)参数指定了学习率的大小；
* -n(--num_iterations)参数指定了优化器求解模型的最大迭代次数。

2. 无载体的攻击场景

&emsp;&emsp;根据用户提供的原始指令音频文件集合，inverse_mfcc.py攻击脚本将从目标指令的MFCC特征向量出发，迭代地逆转MFCC特征提取过程，并将每次迭代的恶意样本音频文件输出至用户指定的目录下。下面，提供一个例子来说明该脚本的使用。

`python attack.py -c ./Audio Samples/Commands/ -m ./Audio Samples/Malicious Samples/ -t ./Audio Samples/Commands.txt -n 5`

* -c(--commands)参数指定了原始指令音频文件集合的目录；\
* -m(--malicious_samples)参数指定了生成的恶意样本音频文件的输出目录；
* -t(--transcriptions)参数指定了包含原始指令文本的文本文件路径，用于输出对应于恶意样本的目标转录结果；
* -n(--num_iterations)参数指定了倒转MFCC特征提取过程的最大迭代次数。


## 攻击结果测试

&emsp;&emsp;我们选择百度和科大讯飞的在线语音识别API（支持中文和英文语音识别）作为攻击对象，输入恶意音频样本文件，得到相应的转录结果输出，此过程不涉及环境噪声、电子噪声的干扰。用户指定待测试音频文件样本所在的目录，使用speech_to_text.py语音识别脚本进行转录识别，最终输出两种系统的识别结果和目标指令的对比。下面，提供一个例子来说明该脚本的使用。

`python speech_to_text.py -d ./Audio Samples/Malicious Samples/ -t ./Audio Samples/Malicious-Commands.txt -o ./Audio Samples/ASR-Results.csv`

* -d(--directory)参数指定了待测试音频样本文件所在的目录；
* -t(--transcriptions)参数指定了包含目标识别结果文本的文本文件路径；
* -o(--output)参数指定了识别结果文件的输出路径，该csv文件共4列，分别为文件名、目标转录结果、实际百度转录结果、实际科大讯飞转录结果。