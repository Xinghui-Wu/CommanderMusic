# 针对自动语音识别系统预处理环节的实用黑盒攻击

## 简介

&emsp;&emsp;西安交通大学团队提出了一种攻击自动语音识别系统的新颖方法。与之前的研究针对语音识别系统底层的机器学习、深度学习模型提出的对抗攻击方法不同的是，本团队提出通过攻击语音识别系统预处理环节来达到对整个系统的攻击，使得系统误判经过特殊修改的音频样本，产生和人耳听觉感知差异较大的转录结果。

&emsp;&emsp;我们首先对攻击场景进行了充分的研究，考虑以某种技术将恶意指令隐蔽地嵌入到任意的歌曲片段中，在保证用户不会察觉到恶意样本的异常的前提下，期望目标语音识别系统能够识别出隐藏于恶意歌曲样本中的指令。我们认为这是一种十分贴近于用户日常生活的实用场景，具备较高的研究价值。

&emsp;&emsp;本团队提出的攻击方法的基本思想是精心设计扰动，将其添加至原始歌曲片段中，期望经过扰动的歌曲片段经过语音特征提取得到的特征向量与原始指令音频的特征向量尽可能相似，在此过程中，还要保持扰动尽可能小以不被察觉。这一基本思想可以抽象成优化模型，编写代码求解优化模型以生成恶意音频样本。

&emsp;&emsp;本团队实现了所提出的针对语音识别系统的黑盒攻击方法，并提供了若干工具用于定制化的攻击，主要包括根据给定输入指令、歌曲载体集合生成恶意样本集合的攻击脚本，给定指令文本合成指令音频文件的语音合成脚本（基于百度语音合成API），给定测试音频文件集合输出转录结果的语音识别脚本（集成了百度和科大讯飞中文语音识别API）。

&emsp;&emsp;下面，将对我们提供的几个工具进行详细的使用说明。


## 运行环境与依赖

&emsp;&emsp;我们仅在以下平台进行了代码测试。

* 操作系统：Ubuntu 16.04.7 LTS (GNU/Linux 4.4.0-190-generic x86_64)
* 解释器：Python 3.7
* 主要第三方库：torch 1.5.0，torchaudio 0.5.0

&emsp;&emsp;完整的第三方库依赖可参见项目根目录下的requirements.txt文件。通过`pip install -r requirements.txt`命令完成环境配置。

&emsp;&emsp;由于代码中使用了PyTorch的优化器进行大规模非线性优化问题的求解，我们建议用户使用**GPU服务器**作为计算平台。


## 数据准备

1. 指令音频文件

&emsp;&emsp;我们提供了中文语音合成脚本text_to_speech.py供用户将指定的字符串文本合成为相应的音频文件。下面，提供一个例子来说明该脚本的使用。

`python text_to_speech.py -c ./Audio Samples/Commands.txt -d ./Audio Samples/Commands/`

* -c(--commands)参数指定了包含目标指令文本的文本文件（每行一段指令文本）的路径；
* -d(--directory)参数指定了语音合成音频文件的保存目录。

2. 载体歌曲文件

&emsp;&emsp;用户可从互联网上下载任意歌曲文件（wav格式），运行我们提供的preprocessing.py脚本将其转换成单声道、16kHz采样率。下面，提供一个例子来说明该脚本的使用。

`python preprocessing.py -s ./Audio Samples/Songs/`

* -s(--song)参数指定了待转换处理的歌曲文件所在的目录。


## 生成恶意音频样本

&emsp;&emsp;根据用户提供的原始指令音频文件集合和原始歌曲文件集合，attack.py攻击脚本将前者中的每一个指令嵌入到后者中的每一首歌曲中，并将恶意样本音频文件和作为对比的干净样本音频文件输出至用户指定的目录下。攻击脚本在进行非线性优化模型求解时，将会使用到用户指定的参数，包括优化器种类、惩罚因子、学习率和最大迭代次数。这些参数值的选取将会显著影响攻击效果。下面，提供一个例子来说明该脚本的使用。

`python attack.py -c ./Audio Samples/Commands/ -s ./Audio Samples/Songs/ -p ./Audio Samples/Pure Samples/ -m ./Audio Samples/Malicious Samples/ -t ./Audio Samples/Commands.txt -o Adam -f 50 -l 0.001 -n 10000`

* -c(--commands)参数指定了原始指令音频文件集合的目录；
* -s(--songs)参数指定了原始歌曲文件集合的目录；
* -p(--pure_samples)参数指定了生成的干净样本音频文件的输出目录；
* -m(--malicious_samples)参数指定了生成的恶意样本音频文件的输出目录；
* -t(--transcriptions)参数指定了包含原始指令文本的文本文件路径，用于输出对应于恶意样本的目标转录结果；
* -o(--optimizer)参数指定了PyTorch内置优化器的种类，目前支持Adam优化器和SGD优化器；
* -f(--penalty_factor)参数指定了惩罚因子的大小，**惩罚因子用于限制优化模型中扰动向量范数对于目标函数的影响程度**，惩罚因子越大，生成的恶意样本隐蔽性越好，但攻击成功率可能欠佳，反之，恶意样本的攻击成功率较为理想，但隐蔽性较差；
* -l(--learning_rate)参数指定了学习率的大小；
* -n(--num_iterations)参数指定了优化器求解模型的最大迭代次数。


## 攻击结果测试

&emsp;&emsp;我们选择百度和科大讯飞的在线中文语音识别API作为攻击对象，输入恶意音频样本文件，得到相应的转录结果输出，此过程不涉及环境噪声、电子噪声的干扰。用户指定待测试音频文件样本所在的目录，使用speech_to_text.py语音识别脚本进行转录识别，最终输出两种系统的识别结果和目标指令的对比。下面，提供一个例子来说明该脚本的使用。

`python speech_to_text.py -d ./Audio Samples/Malicious Samples/ -t ./Audio Samples/Malicious-Commands.txt -o ./Audio Samples/ASR-Results.csv`

* -d(--directory)参数指定了待测试音频样本文件所在的目录；
* -t(--transcriptions)参数指定了包含目标识别结果文本的文本文件路径；
* -o(--output)参数指定了识别结果文件的输出路径，该csv文件共4列，分别为文件名、目标转录结果、实际百度转录结果、实际科大讯飞转录结果。